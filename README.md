# sncf-trafic-prediction

# üöÜ Projet SNCF - Pr√©diction des Retards en Temps R√©el

## üéØ Objectif

Ce projet vise √† **pr√©voir les retards des trains** √† partir de donn√©es de passages en gare, en s'appuyant sur une architecture de **traitement temps r√©el** et un pipeline complet de **Machine Learning**, depuis l'ingestion des donn√©es jusqu'√† la visualisation.

---

## üß± Stack technique

| Composant       | R√¥le                                                                 |
|-----------------|----------------------------------------------------------------------|
| **Docker + Compose** | Conteneurisation et orchestration des services                     |
| **Apache Kafka**     | Ingestion en streaming des donn√©es simul√©es                        |
| **Apache Spark**     | Traitement des donn√©es + entra√Ænement ML avec Spark MLlib         |
| **Delta Lake**       | Format de stockage transactionnel sur Spark                        |
| **Airflow**          | Orchestration des t√¢ches ETL + ML                                  |
| **PostgreSQL**       | Backend pour Airflow                                               |
| **Power BI (DirectQuery)** | Visualisation temps r√©el (optionnelle)                        |
| **Python + Pandas + scikit-learn** | Pr√©paration des donn√©es et export vers Power BI (si besoin) |

---

## ‚öôÔ∏è Architecture du projet

```bash
.
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îî‚îÄ‚îÄ jupyter/              # Dockerfile custom Spark + Delta + Jupyter
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ train_model.py        # Entra√Ænement ML
‚îÇ   ‚îî‚îÄ‚îÄ push_prediction_to_powerbi.py  # Export vers Power BI (API REST)
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îî‚îÄ‚îÄ train_predict_dag.py  # DAG Airflow pour orchestration
‚îú‚îÄ‚îÄ data/                     # Donn√©es brutes
‚îú‚îÄ‚îÄ notebooks/                # Analyses exploratoires
‚îú‚îÄ‚îÄ docker-compose.yml        # Stack compl√®te
‚îî‚îÄ‚îÄ README.md
```

---

## üîÅ Pipeline complet

1. **Kafka simule** des messages de trafic ferroviaire.
2. **Airflow** d√©clenche `train_model.py` (batch ML en Spark).
3. Les pr√©dictions sont stock√©es et/ou envoy√©es √† Power BI.
4. Un deuxi√®me script (`push_prediction_to_powerbi.py`) peut pousser les donn√©es vers un tableau de bord.

---

## ‚úÖ Avancement

| √âtape                                 | Statut  |
|---------------------------------------|---------|
| Environnement Docker complet          | ‚úÖ Fait |
| Kafka + Zookeeper                     | ‚úÖ Fait |
| PostgreSQL (Airflow)                  | ‚úÖ Fait |
| Spark avec Delta Lake                 | ‚úÖ Fait |
| Script d'entra√Ænement ML (Spark)      | ‚úÖ Fait |
| Orchestration avec Airflow            | ‚úÖ Fait |
| Export des pr√©dictions (Power BI)     | ‚úÖ Fait |
| Dashboard Power BI                    | ‚ùå Optionnel (non finalis√©) |

---

## üìä Mesures DAX cr√©√©es dans Power BI

Des mesures cl√©s pour l‚Äôanalyse des performances ferroviaires :
- `Nombre Trajets` : `COUNT(RealTimeData[trip_id])`
- `Retard Moyen (s)` : `AVERAGE(RealTimeData[departure] - RealTimeData[arrival])`
- `Dur√©e Moyenne Parcours (s)` : `AVERAGE(RealTimeData[arrival] - RealTimeData[departure])`

---

## üß† Points forts techniques

- Utilisation de **Delta Lake** pour les performances et l‚Äôatomicit√©.
- Traitement **distribu√© et scalable** avec Spark.
- Architecture **modulaire**, conteneuris√©e, et automatis√©e.
- Support de **traitement batch + streaming**.
- Possibilit√© d‚Äôextension facile vers du temps r√©el complet avec Kafka + Spark Structured Streaming.

---

## ‚ö†Ô∏è Points d'am√©lioration / TODO

- Ajouter des contr√¥les qualit√© dans `train_model.py` (ex : √©liminer valeurs aberrantes).
- Compl√©ter le dashboard Power BI avec des visuels comme :
  - √âvolution des retards par jour/heure
  - Retard moyen par arr√™t (`stop_name`)
  - Carte des retards si coordonn√©es disponibles
- Option : publier un dataset "mock" sur Kaggle ou DataHub pour rendre le projet reproductible.

---

## üöÄ Lancer le projet

```bash
# D√©marrer tous les services
docker-compose up -d --build

# Acc√©der √† Jupyter : http://localhost:8888
# Acc√©der √† Airflow : http://localhost:8080
```

---

## ‚ú® R√©sultat attendu

√Ä chaque ex√©cution automatique ou manuelle du pipeline :
- Les donn√©es sont pr√©trait√©es et enrichies
- Un mod√®le pr√©dit les retards de fin de parcours
- Les r√©sultats sont pr√™ts √† √™tre visualis√©s ou exploit√©s

---

## üôã Auteur

**Aldio [GitHub Username]**  
Projet r√©alis√© dans le cadre d‚Äôun apprentissage Data Engineering / ML Ops.

> N'h√©sitez pas √† me contacter pour une d√©mo technique ou une revue du code !
